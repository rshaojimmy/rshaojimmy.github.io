<!DOCTYPE html>
<html lang="en">


<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Text2Human">

    <title>SeqDeepFake - Project Page</title>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/charts.css/dist/charts.min.css">
    <link id="theme-style" rel="stylesheet" href="./assets/SeqDeepFake/css/seqdeepfake_main.css">
    <link id="theme-style" rel="stylesheet" href="./assets/SeqDeepFake/css/bulma-carousel.min.css">
    <link id="theme-style" rel="stylesheet" href="./assets/SeqDeepFake/css/bulma-slider.min.css">

    <!-- <script type="module" src="./assets/js/background_box.js"></script> -->
    <script type="module" src="./assets/SeqDeepFake/js/background_star.js"></script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="./assets/SeqDeepFake/js/bulma-carousel.min.js"></script>
    <script src="./assets/SeqDeepFake/js/bulma-slider.min.js"></script>
    <script src="./assets/SeqDeepFake/js/index.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-D41DLSC2BJ');
    </script>
</head>

<body>

    <div class="wrapper">

        <section class="section intro-section">
            <div class="intro-container" style="text-align: center;">
                <div class="header">
                    <h3 class="papername">SeqDeepFake: Detecting and Recovering Sequential DeepFake Manipulation
                    </h3>
                </div>
                <ul class="list-unstyled name-list">
                    <li><a href="https://rshaojimmy.github.io/" target="_blank">Rui Shao</a></li>
                    <li><a href="https://tianxingwu.github.io/" target="_blank">Tianxing Wu</a></li>
                    <li><a href="https://liuziwei7.github.io/" target="_blank">Ziwei Liu</a></li>
                </ul>
                <ul class="list-unstyled name-list">
                    <li><a href="https://www.mmlab-ntu.com/index.html" target="_blank">S-Lab, Nanyang Technological University</a></li>
                </ul>
                <div class="title"> <a href="https://eccv2022.ecva.net/"
                        target="_blank">ECCV 2022</a></div>
                        <div style="font-size:large;"><strong>TL;DR:</strong> In this work, we focus on detecting DeepFake manipulation sequences rather than binary lables. </div>

            </div>
            <br>
            <div class="intro-container" style="text-align: center;">
                <!-- <img src='./assets/SeqDeepFake/images/problem_definition.gif' style="width: 80%" /> -->
                <!-- <img src='./assets/SeqDeepFake/images/problem_definition.png' onmouseover="this.src='./assets/SeqDeepFake/images/problem_definition.gif';" onmouseout="this.src='./assets/SeqDeepFake/images/problem_definition.png';"  style="width: 80%" /> -->
                <img src='./assets/SeqDeepFake/images/problem_definition.gif' onmouseover="this.src='./assets/SeqDeepFake/images/problem_definition.png';" onmouseout="this.src='./assets/SeqDeepFake/images/problem_definition.gif';"  style="width: 80%" />
            </div>
        </section>

        <section class='section'>
            <div class="section-title">
                Abstract
            </div>
            <div class="details" style="text-align: justify" ;>
                Since photorealistic faces can be readily generated by facial manipulation technologies nowadays, 
                potential malicious abuse of these technologies has drawn great concerns. Numerous deepfake detection 
                methods are thus proposed. However, existing methods only focus on detecting <i>one-step</i> facial 
                manipulation. As the emergence of easy-accessible facial editing applications, people can easily 
                manipulate facial components using <i>multi-step</i> operations in a sequential manner. This new 
                threat requires us to detect a sequence of facial manipulations, which is vital for both detecting 
                deepfake media and recovering original faces afterwards. Motivated by this observation, we emphasize 
                the need and propose a novel research problem called Detecting Sequential DeepFake Manipulation 
                <b>Seq-DeepFake</b>). Unlike existing deepfake detection task only demanding a binary label prediction, 
                detecting Seq-DeepFake manipulation requires correctly predicting a sequential vector of facial manipulation 
                operations. To support a large-scale investigation, we construct the first <b>Seq-DeepFake dataset</b>, where face 
                images are manipulated sequentially with corresponding annotations of sequential facial manipulation vectors. 
                Based on this new dataset, we cast detecting Seq-DeepFake manipulation as a specific image-to-sequence 
                (<i>e.g.</i> image captioning) task and propose a concise yet effective Seq-DeepFake Transformer 
                (<b>SeqFakeFormer</b>). Moreover, we build a comprehensive benchmark and set up rigorous evaluation protocols 
                and metrics for this new research problem. Extensive experiments demonstrate the effectiveness of SeqFakeFormer. 
                Several valuable observations are also revealed to facilitate future research in more broad deepfake detection problems.
                
            </div>
        </section>

        <section class='section links-section'>
            <div class='section-title'>
                Links
            </div>
            <div class='details links-table'>
                <table>
                    <tr>
                        <td>
                            <div class='links-container'>
                                <a href=' ' target="_blank"><img class='links-cover'
                                        src='./assets/SeqDeepFake/images/PDF_icon.svg' alt='PDF Cover' style="width: 30%"></a>
                            </div>
                        </td>
                        <td>
                            <div class='links-container'>
                                <a href='https://github.com/rshaojimmy/SeqDeepFake' target="_blank"><img class='links-cover'
                                        src='./assets/SeqDeepFake/images/github.png' alt='github icon'></a>
                            </div>
                        </td>
                        <td>
                            <div class='links-container'>
                                <a href='https://lifehkbueduhk-my.sharepoint.com/personal/16483782_life_hkbu_edu_hk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2F16483782%5Flife%5Fhkbu%5Fedu%5Fhk%2FDocuments%2Fdatasets%2FSeq%2DDeepFake&ga=1' target="_blank"><img class='links-cover'
                                        src='./assets/SeqDeepFake/images/onedrive_icon.png' alt='onedrive icon'></a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td><a href=' ' target="_blank">Paper PDF (arXiv)</a></td>
                        <td><a href='https://github.com/rshaojimmy/SeqDeepFake' target="_blank">Code</a></td>
                        <td><a href=' ' target="_blank">Dataset</a>
                        </td>
                    </tr>
                </table>
            </div>
        </section>

    <br>
        <section class="section">
            <div class="section-title">
                Seq-DeepFake Dataset
            </div>
            <div class="details" style="text-align: center;">
                <img class='links-cover' src='./assets/SeqDeepFake/images/dataset.png' , width="80%">
            </div>

        <br>
            <p><b>Seq-DeepFake</b> is the first large-scale dataset for Sequential DeepFake Manipulation Detection. It consists of 
                <b>85k</b> sequentially manipulated face images, each with ground-truth sequence annotation. The dataset 
                includes high diversity manipulation sequences with lengths from 0 to 5, and is generated based on two different 
                facial manipulation methods:
            </p>
            <ul>
                <li><span style="color:#AE2011">Sequential facial components manipulation</span></li>
                <ul>
                    <li><b>35,166</b> number of face images</li>
                    <li><b>28</b> types of manipulation sequences</li>
                </ul>
                <li><span style="color:#0a939d">Sequential facial attributes manipulation</span></li>
                <ul>
                    <li><b>49,920</b> number of face images</li>
                    <li><b>26</b> types of manipulation sequences</li>
                </ul>
            </ul>

            <p>
                Some sample images and their annotations are shown below (<i><b>Mouse Over: the original image</b></i>). 
                For more information about the data structure, annotation details and other properties about the dataset, 
                you can refer to our 
                <a href="https://github.com/rshaojimmy/SeqDeepFake#dataset-preparation" target="_blank">github page</a></li>.
            </p>
        <br>
            <section class="section intro-section">
                <div id="carouselExampleIndicators" class="video-container">
                    <div id="results-carousel" class="carousel is-dark results-carousel video-container-inner">

                        <div class="video item">
                            <img src='./assets/SeqDeepFake/images/teaser/1_edited.png'
                            onmouseover="this.src='./assets/SeqDeepFake/images/teaser/1_orig.png';"
                            onmouseout="this.src='./assets/SeqDeepFake/images/teaser/1_edited.png';"
                            width="220" height="220">
                            <p class="video-caption">
                                <span style="color:#0a939d">Bangs-Smiling</span>
                            </p>
                        </div>

                        <div class="video item">
                            <img src='./assets/SeqDeepFake/images/teaser/2_edited.jpg'
                            onmouseover="this.src='./assets/SeqDeepFake/images/teaser/2_orig.png';"
                            onmouseout="this.src='./assets/SeqDeepFake/images/teaser/2_edited.jpg';"
                            width="220" height="220">
                            <p class="video-caption">
                                <span style="color:#AE2011">eye-lip-nose-eyebrow-hair</span>
                            </p>
                        </div>

                        <div class="video item">
                            <img src='./assets/SeqDeepFake/images/teaser/3_edited.png'
                            onmouseover="this.src='./assets/SeqDeepFake/images/teaser/3_orig.png';"
                            onmouseout="this.src='./assets/SeqDeepFake/images/teaser/3_edited.png';"
                            width="220" height="220">
                            <p class="video-caption">
                                <span style="color:#0a939d">Eyeglasses</span>
                            </p>
                        </div>

                        <div class="video item">
                            <img src='./assets/SeqDeepFake/images/teaser/4_edited.jpg'
                            onmouseover="this.src='./assets/SeqDeepFake/images/teaser/4_orig.png';"
                            onmouseout="this.src='./assets/SeqDeepFake/images/teaser/4_edited.jpg';"
                            width="220" height="220">
                            <p class="video-caption">
                                <span style="color:#AE2011">lip-nose-eye</span>
                            </p>
                        </div>

                        <div class="video item">
                            <img src='./assets/SeqDeepFake/images/teaser/5_edited.jpg'
                            onmouseover="this.src='./assets/SeqDeepFake/images/teaser/5_orig.png';"
                            onmouseout="this.src='./assets/SeqDeepFake/images/teaser/5_edited.jpg';"
                            width="220" height="220">
                            <p class="video-caption">
                                <span style="color:#AE2011">eyebrow-nose</span>
                            </p>
                        </div>

                    </div>
                </div>
            </section>
        </section>

        <section class='section'>
            <div class="section-title">
                Method
            </div>
            <strong><span style="font-size:larger">Proposed SeqFakeFormer</span></strong>
            <p>
                Figure below shows the architecture of proposed Seq-DeepFake Transformer (<b>SeqFakeFormer</b>). 
                We first feed the face image into a CNN to learn features of spatial manipulation regions, 
                and extract their <b>spatial relation</b> via self-attention modules in the encoder. 
                Then <b>sequential relation</b> based on features of spatial relation is modeled to detect 
                the sequential facial manipulation. A spatial enhanced cross-attention module is integrated 
                into the decoder, contributing to a more effective cross-attention.
            </p>
        <br>
            <div class="details" style="text-align: center" ;>
                <img src='./assets/SeqDeepFake/images/SeqFakeFormer.png' style="width: 90%" />
            </div>
            
            <br>
            <strong><span style="font-size:larger">Benchmark results</span></strong>
            <p>
                We tabulate the first benchmark for detecting sequential facial manipulation in Table 1~3. 
                SeqFakeFormer outperforms all SOTA deepfake detection methods in both manipulation types, 
                under two evaluation metrics.
            </p>

            <br>

            <div class="details" style="text-align: center" ;>
                <img src='./assets/SeqDeepFake/images/table_1.png' style="width: 60%" />
            </div>
            <br>
            <div class="details" style="text-align: center" ;>
                <img src='./assets/SeqDeepFake/images/table_2.png' style="width: 60%" />
            </div>
            <br>
            <div class="details" style="text-align: center" ;>
                <img src='./assets/SeqDeepFake/images/table_3.png' style="width: 60%" />
            </div>

            <br>
            <strong><span style="font-size:larger">Recovery results</span></strong>
            <br>
            <p>
                Examples of comparision between recovery results obtained by the 
                <span style="color:#11ae29"><b>correct inverse sequences (<i>Mouse Out</i>)</b></span> 
                and <span style="color:#f91b02"><b>wrong sequences (<i>Mouse Over</i>)</b></span>. 
                Experiment results show that <b>the sequence order matters</b> for better recovering original images, which 
                proves the importance of detecting DeepFake manipulation sequences.
            </p>
            <br>
            <div class="details" style="text-align: center" ;>
                <img src='./assets/SeqDeepFake/images/recovery_good.png'
                            onmouseover="this.src='./assets/SeqDeepFake/images/recovery_bad.png';"
                            onmouseout="this.src='./assets/SeqDeepFake/images/recovery_good.png';"
                            style="width: 80%">
            </div>
        </section>

        <section class="section">
            <div class="section-title">
                Bibtex
            </div>
            <!-- <div class="details">
                <pre>@article{jiang2022text2human,
        title={Text2Human: Text-Driven Controllable Human Image Generation},
        author={Jiang, Yuming and Yang, Shuai and Qiu, Haonan and Wu, Wayne and Loy, Chen Change and Liu, Ziwei},
        journal={ACM Transactions on Graphics (TOG)},
        volume={41},
        number={4},
        articleno={162},
        pages={1--11},
        year={2022},
        publisher={ACM New York, NY, USA},
        doi={10.1145/3528223.3530104}
}
                    </pre>
            </div> -->
            TBA.
        </section>


        <section class='section'>
            <div class="section-title">
                Acknowledgement
            </div>
            <!-- <p>This study is supported by NTU NAP, MOE AcRF Tier 2 (T2EP20221-0033), and under the RIE2020 Industry
                Alignment Fund â€“ Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and
                in-kind contribution from the industry partner(s).</p> -->
            <p>We referred to the project page of <a href="https://hongfz16.github.io/projects/AvatarCLIP.html">AvatarCLIP</a> when creating this
                project page.</p>
        </section>

    </div>


</body>

</html>